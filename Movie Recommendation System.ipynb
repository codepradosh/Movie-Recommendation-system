{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e016311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3356883f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanha930\\AppData\\Local\\Temp\\ipykernel_19440\\2475798050.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(DATAPATH)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>sentence</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3  False                                                NaN  16000000   \n",
       "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "\n",
       "                               homepage     id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
       "1                                   NaN   8844  tt0113497                en   \n",
       "2                                   NaN  15602  tt0113228                en   \n",
       "3                                   NaN  31357  tt0114885                en   \n",
       "4                                   NaN  11862  tt0113041                en   \n",
       "\n",
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            sentence  ... release_date  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n",
       "1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n",
       "2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n",
       "3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n",
       "4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n",
       "\n",
       "       revenue runtime                                   spoken_languages  \\\n",
       "0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "     status                                            tagline  \\\n",
       "0  Released                                                NaN   \n",
       "1  Released          Roll the dice and unleash the excitement!   \n",
       "2  Released  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3  Released  Friends are the people who let you be yourself...   \n",
       "4  Released  Just When His World Is Back To Normal... He's ...   \n",
       "\n",
       "                         title  video vote_average vote_count  \n",
       "0                    Toy Story  False          7.7     5415.0  \n",
       "1                      Jumanji  False          6.9     2413.0  \n",
       "2             Grumpier Old Men  False          6.5       92.0  \n",
       "3            Waiting to Exhale  False          6.1       34.0  \n",
       "4  Father of the Bride Part II  False          5.7      173.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATAPATH = 'movies_metadata.csv' \n",
    "\n",
    "df = pd.read_csv(DATAPATH)\n",
    "df = df[~df.overview.isna()]\n",
    "df.rename(columns={'overview':'sentence'}, inplace=True)\n",
    "print(len(df))\n",
    "df = df.iloc[:20000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96bc976a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kanha930\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3b9405e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kanha930\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb0d24d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\kanha930\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92115f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning sentences...\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "MIN_WORDS = 4\n",
    "MAX_WORDS = 200\n",
    "\n",
    "PATTERN_S = re.compile(\"\\'s\")  # matches `'s` from text  \n",
    "PATTERN_RN = re.compile(\"\\\\r\\\\n\") #matches `\\r` and `\\n`\n",
    "PATTERN_PUNC = re.compile(r\"[^\\w\\s]\") # matches all non 0-9 A-z whitespace \n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Series of cleaning. String to lower case, remove non words characters and numbers.\n",
    "        text (str): input text\n",
    "    return (str): modified initial text\n",
    "    \"\"\"\n",
    "    text = text.lower()  # lowercase text\n",
    "    text = re.sub(PATTERN_S, ' ', text)\n",
    "    text = re.sub(PATTERN_RN, ' ', text)\n",
    "    text = re.sub(PATTERN_PUNC, ' ', text)\n",
    "    return text\n",
    "\n",
    "def tokenizer(sentence, min_words=MIN_WORDS, max_words=MAX_WORDS, stopwords=STOPWORDS, lemmatize=True):\n",
    "    \"\"\"\n",
    "    Lemmatize, tokenize, crop and remove stop words.\n",
    "    \"\"\"\n",
    "    if lemmatize:\n",
    "        stemmer = WordNetLemmatizer()\n",
    "        tokens = [stemmer.lemmatize(w) for w in word_tokenize(sentence)]\n",
    "    else:\n",
    "        tokens = [w for w in word_tokenize(sentence)]\n",
    "    token = [w for w in tokens if (len(w) > min_words and len(w) < max_words\n",
    "                                                        and w not in stopwords)]\n",
    "    return tokens    \n",
    "\n",
    "\n",
    "def clean_sentences(df):\n",
    "    \"\"\"\n",
    "    Remove irrelavant characters (in new column clean_sentence).\n",
    "    Lemmatize, tokenize words into list of words (in new column tok_lem_sentence).\n",
    "    \"\"\"\n",
    "    print('Cleaning sentences...')\n",
    "    df['clean_sentence'] = df['sentence'].apply(clean_text)\n",
    "    df['tok_lem_sentence'] = df['clean_sentence'].apply(\n",
    "        lambda x: tokenizer(x, min_words=MIN_WORDS, max_words=MAX_WORDS, stopwords=STOPWORDS, lemmatize=True))\n",
    "    return df\n",
    "    \n",
    "df = clean_sentences(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29dc6282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>clean_sentence</th>\n",
       "      <th>tok_lem_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>led by woody  andy  toys live happily in his r...</td>\n",
       "      <td>[led, by, woody, andy, toy, live, happily, in,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>when siblings judy and peter discover an encha...</td>\n",
       "      <td>[when, sibling, judy, and, peter, discover, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>a family wedding reignites the ancient feud be...</td>\n",
       "      <td>[a, family, wedding, reignites, the, ancient, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>cheated on  mistreated and stepped on  the wom...</td>\n",
       "      <td>[cheated, on, mistreated, and, stepped, on, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>just when george banks has recovered from his ...</td>\n",
       "      <td>[just, when, george, bank, ha, recovered, from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20131</th>\n",
       "      <td>After a lifetime of hiding, Chely Wright becom...</td>\n",
       "      <td>after a lifetime of hiding  chely wright becom...</td>\n",
       "      <td>[after, a, lifetime, of, hiding, chely, wright...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20132</th>\n",
       "      <td>In 1989, five black and Latino teenagers from ...</td>\n",
       "      <td>in 1989  five black and latino teenagers from ...</td>\n",
       "      <td>[in, 1989, five, black, and, latino, teenager,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20133</th>\n",
       "      <td>Arkin escapes with his life from the vicious g...</td>\n",
       "      <td>arkin escapes with his life from the vicious g...</td>\n",
       "      <td>[arkin, escape, with, his, life, from, the, vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20134</th>\n",
       "      <td>Remake of a hit film from 1990, \"The Cherry Or...</td>\n",
       "      <td>remake of a hit film from 1990   the cherry or...</td>\n",
       "      <td>[remake, of, a, hit, film, from, 1990, the, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20135</th>\n",
       "      <td>Chronicles the adventures of Franklin Delano R...</td>\n",
       "      <td>chronicles the adventures of franklin delano r...</td>\n",
       "      <td>[chronicle, the, adventure, of, franklin, dela...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "0      Led by Woody, Andy's toys live happily in his ...   \n",
       "1      When siblings Judy and Peter discover an encha...   \n",
       "2      A family wedding reignites the ancient feud be...   \n",
       "3      Cheated on, mistreated and stepped on, the wom...   \n",
       "4      Just when George Banks has recovered from his ...   \n",
       "...                                                  ...   \n",
       "20131  After a lifetime of hiding, Chely Wright becom...   \n",
       "20132  In 1989, five black and Latino teenagers from ...   \n",
       "20133  Arkin escapes with his life from the vicious g...   \n",
       "20134  Remake of a hit film from 1990, \"The Cherry Or...   \n",
       "20135  Chronicles the adventures of Franklin Delano R...   \n",
       "\n",
       "                                          clean_sentence  \\\n",
       "0      led by woody  andy  toys live happily in his r...   \n",
       "1      when siblings judy and peter discover an encha...   \n",
       "2      a family wedding reignites the ancient feud be...   \n",
       "3      cheated on  mistreated and stepped on  the wom...   \n",
       "4      just when george banks has recovered from his ...   \n",
       "...                                                  ...   \n",
       "20131  after a lifetime of hiding  chely wright becom...   \n",
       "20132  in 1989  five black and latino teenagers from ...   \n",
       "20133  arkin escapes with his life from the vicious g...   \n",
       "20134  remake of a hit film from 1990   the cherry or...   \n",
       "20135  chronicles the adventures of franklin delano r...   \n",
       "\n",
       "                                        tok_lem_sentence  \n",
       "0      [led, by, woody, andy, toy, live, happily, in,...  \n",
       "1      [when, sibling, judy, and, peter, discover, an...  \n",
       "2      [a, family, wedding, reignites, the, ancient, ...  \n",
       "3      [cheated, on, mistreated, and, stepped, on, th...  \n",
       "4      [just, when, george, bank, ha, recovered, from...  \n",
       "...                                                  ...  \n",
       "20131  [after, a, lifetime, of, hiding, chely, wright...  \n",
       "20132  [in, 1989, five, black, and, latino, teenager,...  \n",
       "20133  [arkin, escape, with, his, life, from, the, vi...  \n",
       "20134  [remake, of, a, hit, film, from, 1990, the, ch...  \n",
       "20135  [chronicle, the, adventure, of, franklin, dela...  \n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df[['sentence', 'clean_sentence', 'tok_lem_sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "52a7e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Query Sentence\n",
    "\n",
    "query_sentence = 'sherlock holmes with a black funny hat'\n",
    "\n",
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e88d021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_best_indices(m, topk, mask=None):\n",
    "    \"\"\"\n",
    "    Use sum of the cosine distance over all tokens.\n",
    "    m (np.array): cos matrix of shape (nb_in_tokens, nb_dict_tokens)\n",
    "    topk (int): number of indices to return (from high to lowest in order)\n",
    "    \"\"\"\n",
    "    # return the sum on all tokens of cosinus for each sentence\n",
    "    if len(m.shape) > 1:\n",
    "        cos_sim = np.mean(m, axis=0) \n",
    "    else: \n",
    "        cos_sim = m\n",
    "    index = np.argsort(cos_sim)[::-1] # from highest idx to smallest score \n",
    "    if mask is not None:\n",
    "        assert mask.shape == m.shape\n",
    "        mask = mask[index]\n",
    "    else:\n",
    "        mask = np.ones(len(cos_sim))\n",
    "    mask = np.logical_or(cos_sim[index] != 0, mask) #eliminate 0 cosine distance\n",
    "    best_index = index[mask][:topk]  \n",
    "    return best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8c9a007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanha930\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['doe', 'ha', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20000, 49932)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TFIDF Training\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Adapt stop words\n",
    "token_stop = tokenizer(' '.join(STOPWORDS), lemmatize=False)\n",
    "\n",
    "# Fit TFIDF\n",
    "vectorizer = TfidfVectorizer(stop_words=token_stop, tokenizer=tokenizer) \n",
    "tfidf_mat = vectorizer.fit_transform(df['sentence'].values) # -> (num_sentences, num_vocabulary)\n",
    "tfidf_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e0da2aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Earth Destruction'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Prediction\n",
    "\n",
    "query_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5e37cb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 20000)\n",
      "[ 7748  1492  1194  1743  4379 10094  3784  3347  6047  2277]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7772</th>\n",
       "      <td>This Island Earth</td>\n",
       "      <td>[{'id': 9648, 'name': 'Mystery'}, {'id': 12, 'name': 'Adventure'}, {'id': 878, 'name': 'Science Fiction'}, {'id': 27, 'name': 'Horror'}, {'id': 53, 'name': 'Thriller'}]</td>\n",
       "      <td>Aliens have landed and are hiding on Earth, but need Earthâ€™s scientists to help them fight an inter-planetary war.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>Men in Black</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 12, 'name': 'Adventure'}, {'id': 35, 'name': 'Comedy'}, {'id': 878, 'name': 'Science Fiction'}]</td>\n",
       "      <td>Men in Black follows the exploits of agents Kay and Jay, members of a top-secret organization established to monitor and police alien activity on Earth. The two Men in Black find themselves in the middle of the deadly plot by an intergalactic terrorist who has arrived on Earth to assassinate two ambassadors from opposing galaxies. In order to prevent worlds from colliding, the MiB must track down the terrorist and prevent the destruction of Earth. It's just another typical day for the Men in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>The Day the Earth Stood Still</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 878, 'name': 'Science Fiction'}, {'id': 53, 'name': 'Thriller'}]</td>\n",
       "      <td>An alien and a robot land on earth after World War II and tell mankind to be peaceful or face destruction. A classic science fiction film from Robert Wise with an exceptional message.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>Tarzan and the Lost City</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 12, 'name': 'Adventure'}]</td>\n",
       "      <td>Tarzan returns to his homeland of Africa to save his home from destruction.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>My Stepmother is an Alien</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 878, 'name': 'Science Fiction'}]</td>\n",
       "      <td>Trying to rescue her home planet from destruction, a gorgeous extraterrestrial named Celeste arrives on Earth and begins her scientific research. She woos quirky scientist Dr. Steve Mills, a widower with a young daughter. Before long, Celeste finds herself in love with Steve and her new life on Earth, where she experiences true intimacy for the first time. But when she loses sight of her mission, she begins to question where she belongs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>Gojira: Fainaru uÃ´zu</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 12, 'name': 'Adventure'}, {'id': 878, 'name': 'Science Fiction'}, {'id': 14, 'name': 'Fantasy'}, {'id': 53, 'name': 'Thriller'}]</td>\n",
       "      <td>Evil Space Aliens called the Xilians unleashes all the Earth's monsters to lay waste to most of the world's major cities, including Tokyo, New York, Sydney, Shanghai and Paris. It is up to Godzilla and the Earth Defense Force to vanquish the monsters and aliens to rescue the world in the ultimate \"Save the Earth\" battle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3802</th>\n",
       "      <td>Voyage to the Bottom of the Sea</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 18, 'name': 'Drama'}, {'id': 878, 'name': 'Science Fiction'}]</td>\n",
       "      <td>The crew of an atomic submarine battle to save the world from global destruction.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3365</th>\n",
       "      <td>Devil Girl from Mars</td>\n",
       "      <td>[{'id': 878, 'name': 'Science Fiction'}]</td>\n",
       "      <td>An uptight, leather-clad female alien, armed with a raygun and accompanied by a menacing robot, comes to Earth to collect Earth's men as breeding stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>Teenagers from Outer Space</td>\n",
       "      <td>[{'id': 80, 'name': 'Crime'}, {'id': 27, 'name': 'Horror'}, {'id': 878, 'name': 'Science Fiction'}, {'id': 10749, 'name': 'Romance'}, {'id': 53, 'name': 'Thriller'}]</td>\n",
       "      <td>A young alien falls for a pretty teenage Earth girl and they team up to try to stop the plans of his invading cohorts, who intend to use Earth as a food-breeding ground for giant lobsters from their planet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>Cocoon: The Return</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'name': 'Drama'}, {'id': 878, 'name': 'Science Fiction'}]</td>\n",
       "      <td>The old age pensioners that left at the end of the first film come back to earth to visit their relatives. Will they all decide to go back to the planet where no-one grows old, or will they be tempted to stay back on earth, or will they?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        original_title  \\\n",
       "7772                 This Island Earth   \n",
       "1508                      Men in Black   \n",
       "1208     The Day the Earth Stood Still   \n",
       "1759          Tarzan and the Lost City   \n",
       "4398         My Stepmother is an Alien   \n",
       "10124             Gojira: Fainaru uÃ´zu   \n",
       "3802   Voyage to the Bottom of the Sea   \n",
       "3365              Devil Girl from Mars   \n",
       "6070        Teenagers from Outer Space   \n",
       "2295                Cocoon: The Return   \n",
       "\n",
       "                                                                                                                                                                         genres  \\\n",
       "7772   [{'id': 9648, 'name': 'Mystery'}, {'id': 12, 'name': 'Adventure'}, {'id': 878, 'name': 'Science Fiction'}, {'id': 27, 'name': 'Horror'}, {'id': 53, 'name': 'Thriller'}]   \n",
       "1508                                      [{'id': 28, 'name': 'Action'}, {'id': 12, 'name': 'Adventure'}, {'id': 35, 'name': 'Comedy'}, {'id': 878, 'name': 'Science Fiction'}]   \n",
       "1208                                                                      [{'id': 18, 'name': 'Drama'}, {'id': 878, 'name': 'Science Fiction'}, {'id': 53, 'name': 'Thriller'}]   \n",
       "1759                                                                                                            [{'id': 28, 'name': 'Action'}, {'id': 12, 'name': 'Adventure'}]   \n",
       "4398                                                                                                     [{'id': 35, 'name': 'Comedy'}, {'id': 878, 'name': 'Science Fiction'}]   \n",
       "10124    [{'id': 28, 'name': 'Action'}, {'id': 12, 'name': 'Adventure'}, {'id': 878, 'name': 'Science Fiction'}, {'id': 14, 'name': 'Fantasy'}, {'id': 53, 'name': 'Thriller'}]   \n",
       "3802                                                                     [{'id': 12, 'name': 'Adventure'}, {'id': 18, 'name': 'Drama'}, {'id': 878, 'name': 'Science Fiction'}]   \n",
       "3365                                                                                                                                   [{'id': 878, 'name': 'Science Fiction'}]   \n",
       "6070      [{'id': 80, 'name': 'Crime'}, {'id': 27, 'name': 'Horror'}, {'id': 878, 'name': 'Science Fiction'}, {'id': 10749, 'name': 'Romance'}, {'id': 53, 'name': 'Thriller'}]   \n",
       "2295                                                                        [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'name': 'Drama'}, {'id': 878, 'name': 'Science Fiction'}]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  sentence  \n",
       "7772                                                                                                                                                                                                                                                                                                                                                                                                    Aliens have landed and are hiding on Earth, but need Earthâ€™s scientists to help them fight an inter-planetary war.  \n",
       "1508   Men in Black follows the exploits of agents Kay and Jay, members of a top-secret organization established to monitor and police alien activity on Earth. The two Men in Black find themselves in the middle of the deadly plot by an intergalactic terrorist who has arrived on Earth to assassinate two ambassadors from opposing galaxies. In order to prevent worlds from colliding, the MiB must track down the terrorist and prevent the destruction of Earth. It's just another typical day for the Men in...  \n",
       "1208                                                                                                                                                                                                                                                                                                                               An alien and a robot land on earth after World War II and tell mankind to be peaceful or face destruction. A classic science fiction film from Robert Wise with an exceptional message.  \n",
       "1759                                                                                                                                                                                                                                                                                                                                                                                                                                           Tarzan returns to his homeland of Africa to save his home from destruction.  \n",
       "4398                                                             Trying to rescue her home planet from destruction, a gorgeous extraterrestrial named Celeste arrives on Earth and begins her scientific research. She woos quirky scientist Dr. Steve Mills, a widower with a young daughter. Before long, Celeste finds herself in love with Steve and her new life on Earth, where she experiences true intimacy for the first time. But when she loses sight of her mission, she begins to question where she belongs.  \n",
       "10124                                                                                                                                                                                   Evil Space Aliens called the Xilians unleashes all the Earth's monsters to lay waste to most of the world's major cities, including Tokyo, New York, Sydney, Shanghai and Paris. It is up to Godzilla and the Earth Defense Force to vanquish the monsters and aliens to rescue the world in the ultimate \"Save the Earth\" battle.  \n",
       "3802                                                                                                                                                                                                                                                                                                                                                                                                                                     The crew of an atomic submarine battle to save the world from global destruction.  \n",
       "3365                                                                                                                                                                                                                                                                                                                                                               An uptight, leather-clad female alien, armed with a raygun and accompanied by a menacing robot, comes to Earth to collect Earth's men as breeding stock  \n",
       "6070                                                                                                                                                                                                                                                                                                        A young alien falls for a pretty teenage Earth girl and they team up to try to stop the plans of his invading cohorts, who intend to use Earth as a food-breeding ground for giant lobsters from their planet.  \n",
       "2295                                                                                                                                                                                                                                                                         The old age pensioners that left at the end of the first film come back to earth to visit their relatives. Will they all decide to go back to the planet where no-one grows old, or will they be tempted to stay back on earth, or will they?  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_recommendations_tfidf(sentence, tfidf_mat):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return the database sentences in order of highest cosine similarity relatively to each \n",
    "    token of the target sentence. \n",
    "    \"\"\"\n",
    "    # Embed the query sentence\n",
    "    tokens = [str(tok) for tok in tokenizer(sentence)]\n",
    "    vec = vectorizer.transform(tokens)\n",
    "    # Create list with similarity between query and dataset\n",
    "    mat = cosine_similarity(vec, tfidf_mat)\n",
    "    # Best cosine distance for each token independantly\n",
    "    print(mat.shape)\n",
    "    best_index = extract_best_indices(mat, topk=10)\n",
    "    return best_index\n",
    "\n",
    "\n",
    "best_index = get_recommendations_tfidf(query_sentence, tfidf_mat)\n",
    "print(best_index)\n",
    "\n",
    "display(df[['original_title', 'genres', 'sentence']].iloc[best_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b809a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4655dd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (3.4.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (3.0.11)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (8.1.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (1.10.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (63.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Collecting en-core-web-sm==3.4.1\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.4.1) (3.4.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.11.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (63.4.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.28.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting en-core-web-lg==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.1/en_core_web_lg-3.4.1-py3-none-any.whl (587.7 MB)\n",
      "     -------------------------------------- 587.7/587.7 MB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from en-core-web-lg==3.4.1) (3.4.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.11.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.11)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.21.5)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (8.1.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.10.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.64.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.28.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.4.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (63.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (21.3)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.26.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.1)\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.4.1\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en_core_web_lg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5b325e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spacy trainer\n",
    "\n",
    "import spacy\n",
    "\n",
    "# !python -m spacy download en_core_web_lg\n",
    "\n",
    "#Load pre-trained model\n",
    "nlp = spacy.load(\"en_core_web_lg\") \n",
    "# Apply the model to the sentences\n",
    "df['spacy_sentence'] = df['sentence'].apply(lambda x: nlp(x)) \n",
    "# Retrieve the embedded vectors as a matrix \n",
    "embed_mat = df['spacy_sentence'].values\n",
    "embed_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "898ca64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanha930\\AppData\\Local\\Temp\\ipykernel_19440\\1677401613.py:6: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  mat = np.array([query_embed.similarity(line) for line in embed_mat])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4812</th>\n",
       "      <td>The Angry Red Planet</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 878, 'name': 'Science Fiction'}]</td>\n",
       "      <td>The first manned flight to Mars returns after having been out of communications since it had arrived on Mars. What would it reveal?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 27, 'name': 'Horror'}, {'id': 878, 'name': 'Science Fiction'}]</td>\n",
       "      <td>Melanie Ballard (Natasha Henstridge) is a hard nosed police chief in the year 2025. She and a police snatch squad are sent to Mars to apprehend a dangerous criminal James Williams (Ice Cube). Mars has been occupied by humans for some time and they have set up mining facilities. The mining activities on Mars have unleashed the spirits of alien beings who gradually possess the bodies of the workers. It soon turns out that catching the dangerous fugitive takes a back seat as the alien spirits b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>Mission to Mars</td>\n",
       "      <td>[{'id': 878, 'name': 'Science Fiction'}]</td>\n",
       "      <td>When contact is lost with the crew of the first Mars expedition, a rescue mission is launched to discover their fate.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19362</th>\n",
       "      <td>To Mars by A-Bomb: The Secret History of Project Orion</td>\n",
       "      <td>[{'id': 99, 'name': 'Documentary'}]</td>\n",
       "      <td>Top scientists want to build a nuclear bomb-powered spaceship to visit Mars and the planets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8276</th>\n",
       "      <td>Conquest of Space</td>\n",
       "      <td>[{'id': 878, 'name': 'Science Fiction'}]</td>\n",
       "      <td>A team of American astronauts leave their space station on the first mission to Mars, but the captain's religious beliefs may get in the way.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3856</th>\n",
       "      <td>Red Planet</td>\n",
       "      <td>[{'id': 53, 'name': 'Thriller'}, {'id': 28, 'name': 'Action'}, {'id': 878, 'name': 'Science Fiction'}]</td>\n",
       "      <td>Astronauts search for solutions to save a dying Earth by searching on Mars, only to have the mission go terribly awry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12308</th>\n",
       "      <td>Santa Claus Conquers the Martians</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 12, 'name': 'Adventure'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}, {'id': 14, 'name': 'Fantasy'}, {'id': 878, 'name': 'Science Fiction'}]</td>\n",
       "      <td>Martians, upset that their children have become obsessed with TV shows from Earth which extol the virtues of Santa Claus, start an expedition to Earth to kidnap the one and only Santa. While on Earth, they kidnap two lively children that lead the group of Martians to the North Pole and Santa. The Martians then take Santa and the two children back to Mars with them. Voldar, a particularly grumpy Martian, attempts to do away with the children and Santa before they get to Mars, but their leader...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>Rocketship X-M</td>\n",
       "      <td>[{'id': 878, 'name': 'Science Fiction'}]</td>\n",
       "      <td>Astronauts blast off to explore the moon on Rocketship X-M or \"Rocketship eXploration Moon\". A spacecraft malfunction and some fuel miscalculations cause them to end up landing on Mars. On Mars, evidence of a once powerful civilization is found. The scientists determined that an atomic war destroyed most of the Martians. Those that survived reverted to a caveman like existence.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8582</th>\n",
       "      <td>Robinson Crusoe on Mars</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 878, 'name': 'Science Fiction'}]</td>\n",
       "      <td>Stranded on Mars with only a monkey as a companion, an astronaut must figure out how to find oxygen, water, and food on the lifeless planet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18716</th>\n",
       "      <td>Princess of Mars</td>\n",
       "      <td>[{'id': 14, 'name': 'Fantasy'}, {'id': 878, 'name': 'Science Fiction'}, {'id': 10752, 'name': 'War'}]</td>\n",
       "      <td>Based on the novel by Edgar Rice Burroughs, a US soldier finds himself inexplicably transported to Mars in the midst of a war between two alien races.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               original_title  \\\n",
       "4812                                     The Angry Red Planet   \n",
       "4605                                           Ghosts of Mars   \n",
       "3236                                          Mission to Mars   \n",
       "19362  To Mars by A-Bomb: The Secret History of Project Orion   \n",
       "8276                                        Conquest of Space   \n",
       "3856                                               Red Planet   \n",
       "12308                       Santa Claus Conquers the Martians   \n",
       "3658                                           Rocketship X-M   \n",
       "8582                                  Robinson Crusoe on Mars   \n",
       "18716                                        Princess of Mars   \n",
       "\n",
       "                                                                                                                                                                                                      genres  \\\n",
       "4812                                                                                                                               [{'id': 12, 'name': 'Adventure'}, {'id': 878, 'name': 'Science Fiction'}]   \n",
       "4605                                                                                                    [{'id': 28, 'name': 'Action'}, {'id': 27, 'name': 'Horror'}, {'id': 878, 'name': 'Science Fiction'}]   \n",
       "3236                                                                                                                                                                [{'id': 878, 'name': 'Science Fiction'}]   \n",
       "19362                                                                                                                                                                    [{'id': 99, 'name': 'Documentary'}]   \n",
       "8276                                                                                                                                                                [{'id': 878, 'name': 'Science Fiction'}]   \n",
       "3856                                                                                                  [{'id': 53, 'name': 'Thriller'}, {'id': 28, 'name': 'Action'}, {'id': 878, 'name': 'Science Fiction'}]   \n",
       "12308  [{'id': 28, 'name': 'Action'}, {'id': 12, 'name': 'Adventure'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}, {'id': 14, 'name': 'Fantasy'}, {'id': 878, 'name': 'Science Fiction'}]   \n",
       "3658                                                                                                                                                                [{'id': 878, 'name': 'Science Fiction'}]   \n",
       "8582                                                                                                                                   [{'id': 18, 'name': 'Drama'}, {'id': 878, 'name': 'Science Fiction'}]   \n",
       "18716                                                                                                  [{'id': 14, 'name': 'Fantasy'}, {'id': 878, 'name': 'Science Fiction'}, {'id': 10752, 'name': 'War'}]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  sentence  \n",
       "4812                                                                                                                                                                                                                                                                                                                                                                                   The first manned flight to Mars returns after having been out of communications since it had arrived on Mars. What would it reveal?  \n",
       "4605   Melanie Ballard (Natasha Henstridge) is a hard nosed police chief in the year 2025. She and a police snatch squad are sent to Mars to apprehend a dangerous criminal James Williams (Ice Cube). Mars has been occupied by humans for some time and they have set up mining facilities. The mining activities on Mars have unleashed the spirits of alien beings who gradually possess the bodies of the workers. It soon turns out that catching the dangerous fugitive takes a back seat as the alien spirits b...  \n",
       "3236                                                                                                                                                                                                                                                                                                                                                                                                 When contact is lost with the crew of the first Mars expedition, a rescue mission is launched to discover their fate.  \n",
       "19362                                                                                                                                                                                                                                                                                                                                                                                                                         Top scientists want to build a nuclear bomb-powered spaceship to visit Mars and the planets.  \n",
       "8276                                                                                                                                                                                                                                                                                                                                                                         A team of American astronauts leave their space station on the first mission to Mars, but the captain's religious beliefs may get in the way.  \n",
       "3856                                                                                                                                                                                                                                                                                                                                                                                                Astronauts search for solutions to save a dying Earth by searching on Mars, only to have the mission go terribly awry.  \n",
       "12308  Martians, upset that their children have become obsessed with TV shows from Earth which extol the virtues of Santa Claus, start an expedition to Earth to kidnap the one and only Santa. While on Earth, they kidnap two lively children that lead the group of Martians to the North Pole and Santa. The Martians then take Santa and the two children back to Mars with them. Voldar, a particularly grumpy Martian, attempts to do away with the children and Santa before they get to Mars, but their leader...  \n",
       "3658                                                                                                                          Astronauts blast off to explore the moon on Rocketship X-M or \"Rocketship eXploration Moon\". A spacecraft malfunction and some fuel miscalculations cause them to end up landing on Mars. On Mars, evidence of a once powerful civilization is found. The scientists determined that an atomic war destroyed most of the Martians. Those that survived reverted to a caveman like existence.  \n",
       "8582                                                                                                                                                                                                                                                                                                                                                                          Stranded on Mars with only a monkey as a companion, an astronaut must figure out how to find oxygen, water, and food on the lifeless planet.  \n",
       "18716                                                                                                                                                                                                                                                                                                                                                               Based on the novel by Edgar Rice Burroughs, a US soldier finds himself inexplicably transported to Mars in the midst of a war between two alien races.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_spacy(model, query_sentence, embed_mat, topk=5):\n",
    "    \"\"\"\n",
    "    Predict the topk sentences after applying spacy model.\n",
    "    \"\"\"\n",
    "    query_embed = model(query_sentence)\n",
    "    mat = np.array([query_embed.similarity(line) for line in embed_mat])\n",
    "    # keep if vector has a norm\n",
    "    mat_mask = np.array(\n",
    "        [True if line.vector_norm else False for line in embed_mat])\n",
    "    best_index = extract_best_indices(mat, topk=topk, mask=mat_mask)\n",
    "    return best_index\n",
    "\n",
    "# Predict\n",
    "predict_spacy(nlp, query_sentence, embed_mat)\n",
    "display(df[['original_title', 'genres', 'sentence']].iloc[best_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25e76e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25185210, 33081030)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word 2 Vec\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "# Create model\n",
    "word2vec_model = Word2Vec(min_count=0, workers = 8, vector_size=300) \n",
    "# Prepare vocab\n",
    "word2vec_model.build_vocab(df.tok_lem_sentence.values)\n",
    "# Train\n",
    "word2vec_model.train(df.tok_lem_sentence.values, total_examples=word2vec_model.corpus_count, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "887efdcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_title  \\\n",
       "0      Toy Story   \n",
       "0      Toy Story   \n",
       "0      Toy Story   \n",
       "0      Toy Story   \n",
       "0      Toy Story   \n",
       "0      Toy Story   \n",
       "0      Toy Story   \n",
       "0      Toy Story   \n",
       "0      Toy Story   \n",
       "0      Toy Story   \n",
       "\n",
       "                                                                                             genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]   \n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]   \n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]   \n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]   \n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]   \n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]   \n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]   \n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]   \n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]   \n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                          sentence  \n",
       "0  Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.  \n",
       "0  Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.  \n",
       "0  Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.  \n",
       "0  Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.  \n",
       "0  Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.  \n",
       "0  Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.  \n",
       "0  Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.  \n",
       "0  Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.  \n",
       "0  Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.  \n",
       "0  Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Prediction\n",
    "\n",
    "def is_word_in_model(word, model):\n",
    "    \"\"\"\n",
    "    Check on individual words ``word`` that it exists in ``model``.\n",
    "    \"\"\"\n",
    "    assert type(model).__name__ == 'KeyedVectors'\n",
    "    is_in_vocab = word in model.key_to_index.keys()\n",
    "    return is_in_vocab\n",
    "\n",
    "def predict_w2v(query_sentence, dataset, model, topk=10):\n",
    "    query_sentence = query_sentence.split()\n",
    "    in_vocab_list, best_index = [], [0]*topk\n",
    "    for w in query_sentence:\n",
    "        # remove unseen words from query sentence\n",
    "        if is_word_in_model(w, model.wv):\n",
    "            in_vocab_list.append(w)\n",
    "    # Retrieve the similarity between two words as a distance\n",
    "    if len(in_vocab_list) > 0:\n",
    "        sim_mat = np.zeros(len(dataset))  # TO DO\n",
    "        for i, data_sentence in enumerate(dataset):\n",
    "            if data_sentence:\n",
    "                sim_sentence = model.wv.n_similarity(\n",
    "                        in_vocab_list, data_sentence)\n",
    "            else:\n",
    "                sim_sentence = 0\n",
    "            sim_mat[i] = np.array(sim_sentence)\n",
    "        # Take the five highest norm\n",
    "        best_index = np.argsort(sim_mat)[::-1][:topk]\n",
    "    return best_index\n",
    "\n",
    "# Predict\n",
    "best_index = predict_w2v(query_sentence, df['tok_lem_sentence'].values, word2vec_model)    \n",
    "display(df[['original_title', 'genres', 'sentence']].iloc[best_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fd872835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 325.07 seconds\n"
     ]
    }
   ],
   "source": [
    "#Transformers\n",
    "#Pretrained Transformer\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "start_time = time.time()\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "corpus_embeddings = model.encode(df.sentence.values, convert_to_tensor=True)\n",
    "#query_embedding = model.encode(query_sentence, convert_to_tensor=True)\n",
    "\n",
    "\n",
    "# code to be executed\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken: {:.2f} seconds\".format(end_time - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b1d92230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: the story of a waitress\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "original_title                                                                                                                                                                              The Princess and the Frog\n",
       "genres                                                                           [{'id': 10749, 'name': 'Romance'}, {'id': 10751, 'name': 'Family'}, {'id': 16, 'name': 'Animation'}, {'id': 10402, 'name': 'Music'}]\n",
       "sentence          A waitress, desperate to fulfill her dreams as a restaurant owner, is set on a journey to turn a frog prince back into a human being, but she has to do face the same problem after she kisses him.\n",
       "Name: 14496, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "original_title                                                                                                                                       WiseGirls\n",
       "genres                               [{'id': 28, 'name': 'Action'}, {'id': 35, 'name': 'Comedy'}, {'id': 18, 'name': 'Drama'}, {'id': 53, 'name': 'Thriller'}]\n",
       "sentence          A new waitress working at an Italian restaurant in New York City finds herself entangled in a mob-run underworld of drug dealing and murder.\n",
       "Name: 5873, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "original_title                                                                                                                                                                                                                                                                                                                                                Fauteuils d'orchestre\n",
       "genres                                                                                                                                                                                                                                                                                [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'name': 'Drama'}, {'id': 10749, 'name': 'Romance'}]\n",
       "sentence          A young woman arrives in Paris where she finds a job as a waitress in bar next on Avenue Montaigne that caters to the surrounding theaters and the wealthy inhabitants of the area. She will meet a pianist, a famous actress and a great art collector, and become acquainted with the \"luxurious\" world her grandmother has told her about since her childhood.\n",
       "Name: 11700, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.05 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "start_time = time.time()\n",
    "query_sentence = 'the story of a waitress'\n",
    "query_embedding = model.encode(query_sentence, convert_to_tensor=True)\n",
    "# We use cosine-similarity and torch.topk to find the highest 3 scores\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "top_results = torch.topk(cos_scores, k=3)\n",
    "\n",
    "print(\"\\n\\n======================\\n\\n\")\n",
    "print(\"Query:\", query_sentence)\n",
    "print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "for score, idx in zip(top_results[0], top_results[1]):\n",
    "    score = score.cpu().data.numpy() \n",
    "    idx = idx.cpu().data.numpy()\n",
    "    display(df[['original_title', 'genres', 'sentence']].iloc[idx]) \n",
    "    \n",
    "end_time = time.time()\n",
    "print(\"Time taken: {:.2f} seconds\".format(end_time - start_time))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d472842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel, pipeline\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "BERT_BATCH_SIZE = 4\n",
    "MODEL_NAME = 'sentence-transformers/paraphrase-MiniLM-L6-v2'\n",
    "\n",
    "class BertModel:\n",
    "    def __init__(self, model_name, device=-1, small_memory=True, batch_size=BERT_BATCH_SIZE):\n",
    "        self.model_name = model_name\n",
    "        self._set_device(device)\n",
    "        self.small_device = 'cpu' if small_memory else self.device\n",
    "        self.batch_size = batch_size\n",
    "        self.load_pretrained_model()\n",
    "\n",
    "    def _set_device(self, device):\n",
    "        if device == -1 or device == 'cpu':\n",
    "            self.device = 'cpu'\n",
    "        elif device == 'cuda' or device == 'gpu':\n",
    "            self.device = 'cuda'\n",
    "        elif isinstance(device, int) or isinstance(device, float):\n",
    "            self.device = 'cuda'\n",
    "        else:  # default\n",
    "            self.device = torch.device(\n",
    "                \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def load_pretrained_model(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModel.from_pretrained(self.model_name)\n",
    "        device = -1 if self.device == 'cpu' else 0\n",
    "        self.pipeline = pipeline('feature-extraction',\n",
    "                                 model=self.model, tokenizer=self.tokenizer, device=device)\n",
    "\n",
    "    def embed(self, data):\n",
    "        \"\"\" Create the embedded matrice from original sentences \"\"\"\n",
    "        nb_batchs = 1 if (len(data) < self.batch_size) else len(\n",
    "            data) // self.batch_size\n",
    "        batchs = np.array_split(data, nb_batchs)\n",
    "        mean_pooled = []\n",
    "        for batch in tqdm(batchs, total=len(batchs), desc='Training...'):\n",
    "            mean_pooled.append(self.transform(batch))\n",
    "        mean_pooled_tensor = torch.tensor(\n",
    "            len(data), dtype=float).to(self.small_device)\n",
    "        mean_pooled = torch.cat(mean_pooled, out=mean_pooled_tensor)\n",
    "        self.embed_mat = mean_pooled\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_pooling(model_output, attention_mask):\n",
    "        token_embeddings = model_output[0]\n",
    "        input_mask_expanded = attention_mask.unsqueeze(\n",
    "            -1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    def transform(self, data):\n",
    "        if 'str' in data.__class__.__name__:\n",
    "            data = [data]\n",
    "        data = list(data)\n",
    "        token_dict = self.tokenizer(\n",
    "            data,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\")\n",
    "        token_dict = self.to(token_dict, self.device)\n",
    "        with torch.no_grad():\n",
    "            token_embed = self.model(**token_dict)\n",
    "        # each of the 512 token has a 768 or 384-d vector depends on model)\n",
    "        attention_mask = token_dict['attention_mask']\n",
    "        # average pooling of masked embeddings\n",
    "        mean_pooled = self.mean_pooling(\n",
    "            token_embed, attention_mask)\n",
    "        mean_pooled = mean_pooled.to(self.small_device)\n",
    "        return mean_pooled\n",
    "    \n",
    "    def to(self, data: dict, device: str):\n",
    "        \"\"\"Send all values to device by calling v.to(device)\"\"\"\n",
    "        data = {k: v.to(device) for k, v in data.items()}\n",
    "        return data\n",
    "\n",
    "    def predict(self, in_sentence, topk=3):\n",
    "        input_vec = self.transform(in_sentence)\n",
    "        mat = cosine_similarity(input_vec, self.embed_mat)\n",
    "        # best cos sim for each token independantly\n",
    "        best_index = extract_best_indices(mat, topk=topk)\n",
    "        return best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9d5f530d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6340ae72f7254b728905ba228035dacd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanha930\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kanha930\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed0a0da68c3418683bc8e87edbe21f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea4080c60674953ac7d2785ccb083be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21002ac6e83e41daac4e058b886ba735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bdcedb800ce44eb8a45d8c2aed6f5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddfb23736c44da98f1a3f7291183f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [13:32<00:00,  6.15it/s]\n",
      "C:\\Users\\kanha930\\AppData\\Local\\Temp\\ipykernel_19440\\475789478.py:47: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [20000, 384]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\Resize.cpp:24.)\n",
      "  mean_pooled = torch.cat(mean_pooled, out=mean_pooled_tensor)\n"
     ]
    }
   ],
   "source": [
    "# CPU training\n",
    "bert_model = BertModel(model_name=MODEL_NAME, batch_size=BERT_BATCH_SIZE)\n",
    "bert_model.embed(df.sentence.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7e5acc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cu110/torch_stable.html\n",
      "Requirement already satisfied: torch in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (0.14.1)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-0.13.1-cp39-cp39-win_amd64.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 6.2 MB/s eta 0:00:00\n",
      "Collecting torchtext\n",
      "  Downloading torchtext-0.14.1-cp39-cp39-win_amd64.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 9.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from torchtext) (4.64.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\kanha930\\anaconda3\\lib\\site-packages (from tqdm->torchtext) (0.4.5)\n",
      "Installing collected packages: torchtext, torchaudio\n",
      "Successfully installed torchaudio-0.13.1 torchtext-0.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio torchtext -f https://download.pytorch.org/whl/cu110/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cb367572",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19440\\428054192.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# GPU training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbert_model_gpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBERT_BATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mbert_model_gpu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19440\\475789478.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_name, device, small_memory, batch_size)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmall_device\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cpu'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msmall_memory\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_pretrained_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19440\\475789478.py\u001b[0m in \u001b[0;36mload_pretrained_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cpu'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         self.pipeline = pipeline('feature-extraction',\n\u001b[0m\u001b[0;32m     35\u001b[0m                                  model=self.model, tokenizer=self.tokenizer, device=device)\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"device\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpipeline_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, tokenizer, feature_extractor, modelcard, framework, task, args_parser, device, binary_output, **kwargs)\u001b[0m\n\u001b[0;32m    776\u001b[0m         \u001b[1;31m# Special handling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"pt\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 778\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[1;31m# Update config with task specific parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1680\u001b[0m             )\n\u001b[0;32m   1681\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1682\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1684\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 989\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    990\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m     def register_backward_hook(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    639\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    639\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    662\u001b[0m             \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m                 \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    665\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    985\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[0;32m    986\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[1;32m--> 987\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    220\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# GPU training\n",
    "bert_model_gpu = BertModel(model_name=MODEL_NAME, batch_size=BERT_BATCH_SIZE, device='cuda')\n",
    "bert_model_gpu.transform(df.sentence.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ca52cc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11092</th>\n",
       "      <td>à¤•à¥ƒà¤·</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 878, 'name': 'Science Fiction'}]</td>\n",
       "      <td>Krishna (Roshan) is born with magical powers - a legacy from his father. Priya (Chopra) comes into his life and becomes his world. When she beckons him to Singapore, he follows. In Singapore, Dr. Siddhant Arya (Shah), the megalomaniac scientist is on the verge of changing the future forever. Only one man stands between Dr. Siddharth Arya and his destructive dreams. To block his ruthless ambitions -- Krishna must become Krrish.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20091</th>\n",
       "      <td>KumarÃ©</td>\n",
       "      <td>[{'id': 99, 'name': 'Documentary'}]</td>\n",
       "      <td>A documentary about a man who impersonates a wise Indian Guru and builds a following in Arizona. At the height of his popularity, the Guru KumarÃ© must reveal his true identity to his disciples and unveil his greatest teaching of all.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7798</th>\n",
       "      <td>Samsara</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 18, 'name': 'Drama'}, {'id': 12, 'name': 'Adventure'}]</td>\n",
       "      <td>A love story situated in the Himalayas. A Buddhist monk can't choose between life and the way of the Buddha.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      original_title  \\\n",
       "11092            à¤•à¥ƒà¤·   \n",
       "20091         KumarÃ©   \n",
       "7798         Samsara   \n",
       "\n",
       "                                                                                                 genres  \\\n",
       "11092                            [{'id': 28, 'name': 'Action'}, {'id': 878, 'name': 'Science Fiction'}]   \n",
       "20091                                                               [{'id': 99, 'name': 'Documentary'}]   \n",
       "7798   [{'id': 10749, 'name': 'Romance'}, {'id': 18, 'name': 'Drama'}, {'id': 12, 'name': 'Adventure'}]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                             sentence  \n",
       "11092  Krishna (Roshan) is born with magical powers - a legacy from his father. Priya (Chopra) comes into his life and becomes his world. When she beckons him to Singapore, he follows. In Singapore, Dr. Siddhant Arya (Shah), the megalomaniac scientist is on the verge of changing the future forever. Only one man stands between Dr. Siddharth Arya and his destructive dreams. To block his ruthless ambitions -- Krishna must become Krrish.  \n",
       "20091                                                                                                                                                                                                       A documentary about a man who impersonates a wise Indian Guru and builds a following in Arizona. At the height of his popularity, the Guru KumarÃ© must reveal his true identity to his disciples and unveil his greatest teaching of all.  \n",
       "7798                                                                                                                                                                                                                                                                                                                                     A love story situated in the Himalayas. A Buddhist monk can't choose between life and the way of the Buddha.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.11 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "query_sentence = 'kRISHNA'\n",
    "indices = bert_model.predict(query_sentence)\n",
    "display(df[['original_title', 'genres', 'sentence']].iloc[indices])\n",
    "end_time = time.time()\n",
    "print(\"Time taken: {:.2f} seconds\".format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73db2647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa13e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f5f1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faedd31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e578fb20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194f75e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e1aa12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b289a601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
